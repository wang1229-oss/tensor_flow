{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==============================================\n",
        "# ğŸ“¦ 1ï¸âƒ£ å®‰è£ä¾è³´èˆ‡ TensorFlow Models (é©ç”¨ Python 3.12)\n",
        "# ==============================================\n",
        "!apt-get install -qq protobuf-compiler python3-dev python3-pip\n",
        "\n",
        "# å®‰è£æ–°ç‰ˆ TensorFlow èˆ‡ç›¸é—œå¥—ä»¶\n",
        "!pip install tensorflow==2.19.1 tensorflow_io==0.37.1 matplotlib opencv-python pillow lxml Cython contextlib2 tf_slim\n",
        "\n",
        "# ==============================================\n",
        "# ğŸ“¦ 2ï¸âƒ£ ä¸‹è¼‰èˆ‡å®‰è£ TensorFlow Models\n",
        "# ==============================================\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "# é€²å…¥ models/research è³‡æ–™å¤¾\n",
        "%cd /content/models/research\n",
        "\n",
        "# ç·¨è­¯ .proto æª”æ¡ˆ\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# å®‰è£ Object Detection API\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python3 -m pip install .\n",
        "\n",
        "\n",
        "# å›åˆ°ä¸»ç›®éŒ„\n",
        "%cd /content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EYvnecjx2ll",
        "outputId": "d1394b86-8a14-43b6-f9fa-b4f7fe4df03d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Reading database ... 125081 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-pkg-resources_68.1.2-2~jammy3_all.deb ...\n",
            "Unpacking python3-pkg-resources (68.1.2-2~jammy3) over (59.6.0-1.2ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../python3-setuptools_68.1.2-2~jammy3_all.deb ...\n",
            "Unpacking python3-setuptools (68.1.2-2~jammy3) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.7_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.7) ...\n",
            "Setting up python3-pkg-resources (68.1.2-2~jammy3) ...\n",
            "Setting up python3-setuptools (68.1.2-2~jammy3) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.7) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting tensorflow==2.19.1\n",
            "  Downloading tensorflow-2.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting tensorflow_io==0.37.1\n",
            "  Downloading tensorflow_io-0.37.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (5.4.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (3.0.12)\n",
            "Collecting contextlib2\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.1) (0.5.3)\n",
            "Collecting tensorflow-io-gcs-filesystem==0.37.1 (from tensorflow_io==0.37.1)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow==2.19.1) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.19.1) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.19.1) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.19.1) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.1) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.1) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.1) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow==2.19.1) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow==2.19.1) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow==2.19.1) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.19.1) (0.1.2)\n",
            "Downloading tensorflow-2.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (645.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m645.0/645.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io-0.37.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m130.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Installing collected packages: tensorflow-io-gcs-filesystem, contextlib2, tensorflow_io, tensorflow\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.19.0\n",
            "    Uninstalling tensorflow-2.19.0:\n",
            "      Successfully uninstalled tensorflow-2.19.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.19.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed contextlib2-21.6.0 tensorflow-2.19.1 tensorflow-io-gcs-filesystem-0.37.1 tensorflow_io-0.37.1\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 102831, done.\u001b[K\n",
            "remote: Counting objects: 100% (172/172), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 102831 (delta 129), reused 77 (delta 77), pack-reused 102659 (from 3)\u001b[K\n",
            "Receiving objects: 100% (102831/102831), 642.85 MiB | 37.57 MiB/s, done.\n",
            "Resolving deltas: 100% (74276/74276), done.\n",
            "/content/models/research\n",
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3 (from object_detection==0.1)\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam (from object_detection==0.1)\n",
            "  Downloading apache_beam-2.69.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (11.3.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (5.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (3.10.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (3.0.12)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (21.6.0)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (1.17.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (2.0.10)\n",
            "Collecting lvis (from object_detection==0.1)\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl.metadata (856 bytes)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (1.16.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (2.2.2)\n",
            "Collecting tf-models-official>=2.5.1 (from object_detection==0.1)\n",
            "  Downloading tf_models_official-2.19.1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (3.10.0)\n",
            "Collecting pyparsing==2.4.7 (from object_detection==0.1)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting sacrebleu<=2.2.0 (from object_detection==0.1)\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl.metadata (55 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu<=2.2.0->object_detection==0.1)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2.0.2)\n",
            "Collecting colorama (from sacrebleu<=2.2.0->object_detection==0.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.185.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.7.4.5)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.16.1)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.9.9)\n",
            "Requirement already satisfied: tf-keras>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.19.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (6.0.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.12.0.88)\n",
            "Collecting seqeval (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.2.1)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.2.2)\n",
            "Collecting ai-edge-litert>=1.0.1 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading ai_edge_litert-2.0.2-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: tensorflow~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.19.1)\n",
            "Requirement already satisfied: tensorflow-text~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.19.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->object_detection==0.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->object_detection==0.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->object_detection==0.1) (2025.2)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from tf-slim->object_detection==0.1) (1.4.0)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->object_detection==0.1)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cryptography<48.0.0,>=39.0.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (43.0.3)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (3.11.4)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->object_detection==0.1)\n",
            "  Downloading fastavro-1.12.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache-beam->object_detection==0.1)\n",
            "  Downloading fasteners-0.20-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading grpcio-1.65.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httplib2<0.23.0,>=0.8 (from apache-beam->object_detection==0.1)\n",
            "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (4.25.1)\n",
            "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading objsize-0.7.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (25.0)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pymongo-4.15.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<7.0.0.dev0,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (5.29.5)\n",
            "Collecting pydot<2,>=1.2.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting redis<6,>=5.0.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading redis-5.3.1-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.4 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (2.32.4)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (4.15.0)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (0.25.0)\n",
            "Collecting beartype<0.22.0,>=0.21.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading beartype-0.21.0-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: pyarrow<19.0.0,>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (18.1.0)\n",
            "Collecting pyarrow-hotfix<1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lvis->object_detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from lvis->object_detection==0.1) (1.4.9)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.12/dist-packages (from lvis->object_detection==0.1) (4.12.0.88)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->object_detection==0.1) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->object_detection==0.1) (4.60.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow_io->object_detection==0.1) (0.37.1)\n",
            "Collecting backports.strenum (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading backports_strenum-1.2.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1) (25.9.23)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1) (4.67.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<48.0.0,>=39.0.0->apache-beam->object_detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.28.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (4.2.0)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.28.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (3.11)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (8.0.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (75.2.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object_detection==0.1)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: PyJWT>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from redis<6,>=5.0.0->apache-beam->object_detection==0.1) (2.10.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (2.19.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object_detection==0.1) (0.1.9)\n",
            "INFO: pip is looking at multiple versions of tensorflow-model-optimization to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.7.4-py2.py3-none-any.whl.metadata (914 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl.metadata (910 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl.metadata (910 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.7.1-py2.py3-none-any.whl.metadata (910 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl.metadata (910 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl.metadata (911 bytes)\n",
            "INFO: pip is still looking at multiple versions of tensorflow-model-optimization to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl.metadata (911 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.4.1-py2.py3-none-any.whl.metadata (911 bytes)\n",
            "Collecting tensorflow-hub>=0.6.0 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading tensorflow_hub-0.16.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading tensorflow_hub-0.14.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "  Downloading tensorflow_hub-0.13.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.11.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.10.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.9.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.8.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.7.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "  Downloading tensorflow_hub-0.6.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting ml-dtypes (from keras->object_detection==0.1)\n",
            "  Downloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "  Downloading ml_dtypes-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting h5py (from keras->object_detection==0.1)\n",
            "  Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading h5py-3.15.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading h5py-3.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "  Downloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "  Downloading h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "  Downloading h5py-3.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting tensorflow~=2.19.0 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Using cached tensorflow-2.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "  Downloading tensorflow-2.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting opencv-python>=4.1.0.25 (from lvis->object_detection==0.1)\n",
            "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting numpy>=1.17 (from sacrebleu<=2.2.0->object_detection==0.1)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (4.9.1)\n",
            "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python-headless (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->object_detection==0.1) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->object_detection==0.1) (2.19.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.6.1)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.8.2)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.13.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2.3)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.17.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.45.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<48.0.0,>=39.0.0->apache-beam->object_detection==0.1) (2.23)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (3.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (5.5.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->object_detection==0.1) (0.1.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (3.6.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.1.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.12/dist-packages (from simple_parsing->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.0.3)\n",
            "Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_models_official-2.19.1-py2.py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apache_beam-2.69.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Downloading ai_edge_litert-2.0.2-cp312-cp312-manylinux_2_27_x86_64.whl (91.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.1/91.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beartype-0.21.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.12.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.20-py3-none-any.whl (18 kB)\n",
            "Downloading grpcio-1.65.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m138.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading objsize-0.7.1-py3-none-any.whl (11 kB)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m129.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
            "Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Downloading pymongo-4.15.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.3.1-py3-none-any.whl (272 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backports_strenum-1.2.8-py3-none-any.whl (7.9 kB)\n",
            "Building wheels for collected packages: object_detection, avro-python3, crcmod, hdfs, seqeval, docopt\n",
            "  Building wheel for object_detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=1697325 sha256=f89fda7e97b3e0905810e7b01ccac4ab92417a93abb352f4f2160b580889aed4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1zc4rg00/wheels/93/ad/c5/62cdd10f6d842d66f3d05020591434c5aefd0cdea6bcd6f0ff\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43993 sha256=b95094e349478ebfedf3e1c7c3d8324f252de50afb69447eb28aaefffe7e9fcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/82/f4/b7126d86d6a404dd59a822fad5f169000deee5f61f7c88580c\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp312-cp312-linux_x86_64.whl size=31831 sha256=53d60150b5565ad428f53157718be7e10a20f5c6e699cdc852836cc03c5370b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/08/0b/caa8b1380122cbfe6a03eaccbec0f63c67e619af4e30ca5e2a\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=570279c5ef610f0459ef4f540ffac5cfbeda52f178fd52acb2e29c058f4667d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ae/d9/536505928dd3a458b206013b02625df8f12d22fa154f2bfd65\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=f3355a715dfed2cf6f9276e953ceb8b127a41f22ab5f5c1cdc74e5432f705edf\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=95833cc6282b7ca233fd682aedc707a9609e499c42d10cb546c2bedf58da6bd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
            "Successfully built object_detection avro-python3 crcmod hdfs seqeval docopt\n",
            "Installing collected packages: docopt, crcmod, redis, pyparsing, pyarrow-hotfix, portalocker, objsize, numpy, jsonpickle, grpcio, fasteners, fastavro, dnspython, colorama, beartype, backports.strenum, avro-python3, sacrebleu, pymongo, pydot, opencv-python-headless, opencv-python, httplib2, hdfs, ai-edge-litert, tensorflow-model-optimization, seqeval, lvis, apache-beam, tf-models-official, object_detection\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.5\n",
            "    Uninstalling pyparsing-3.2.5:\n",
            "      Successfully uninstalled pyparsing-3.2.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: jsonpickle\n",
            "    Found existing installation: jsonpickle 4.1.1\n",
            "    Uninstalling jsonpickle-4.1.1:\n",
            "      Successfully uninstalled jsonpickle-4.1.1\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.76.0\n",
            "    Uninstalling grpcio-1.76.0:\n",
            "      Successfully uninstalled grpcio-1.76.0\n",
            "  Attempting uninstall: beartype\n",
            "    Found existing installation: beartype 0.22.4\n",
            "    Uninstalling beartype-0.22.4:\n",
            "      Successfully uninstalled beartype-0.22.4\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 3.0.4\n",
            "    Uninstalling pydot-3.0.4:\n",
            "      Successfully uninstalled pydot-3.0.4\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.12.0.88\n",
            "    Uninstalling opencv-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-4.12.0.88\n",
            "  Attempting uninstall: httplib2\n",
            "    Found existing installation: httplib2 0.31.0\n",
            "    Uninstalling httplib2-0.31.0:\n",
            "      Successfully uninstalled httplib2-0.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires grpcio>=1.71.2, but you have grpcio 1.65.5 which is incompatible.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.19.1 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ai-edge-litert-2.0.2 apache-beam-2.69.0 avro-python3-1.10.2 backports.strenum-1.2.8 beartype-0.21.0 colorama-0.4.6 crcmod-1.7 dnspython-2.8.0 docopt-0.6.2 fastavro-1.12.1 fasteners-0.20 grpcio-1.65.5 hdfs-2.7.3 httplib2-0.22.0 jsonpickle-3.4.2 lvis-0.5.3 numpy-1.26.4 object_detection-0.1 objsize-0.7.1 opencv-python-4.11.0.86 opencv-python-headless-4.11.0.86 portalocker-3.2.0 pyarrow-hotfix-0.7 pydot-1.4.2 pymongo-4.15.3 pyparsing-2.4.7 redis-5.3.1 sacrebleu-2.2.0 seqeval-1.2.2 tensorflow-model-optimization-0.8.0 tf-models-official-2.19.1\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å»ºç«‹å¿…è¦è³‡æ–™å¤¾\n",
        "import os\n",
        "\n",
        "os.makedirs(\"/content/images/train\", exist_ok=True)\n",
        "os.makedirs(\"/content/images/test\", exist_ok=True)\n",
        "os.makedirs(\"/content/annotations\", exist_ok=True)\n",
        "\n",
        "print(\"âœ… è³‡æ–™å¤¾å»ºç«‹å®Œæˆ\")\n",
        "\n",
        "# ä¸‹è¼‰ xml_to_csv.py è…³æœ¬\n",
        "!wget -q https://raw.githubusercontent.com/datitran/raccoon_dataset/master/xml_to_csv.py -O /content/xml_to_csv.py\n",
        "print(\"âœ… xml_to_csv.py å·²ä¸‹è¼‰\")\n",
        "\n",
        "# ä¸‹è¼‰ generate_tfrecord.py è…³æœ¬\n",
        "!wget -q https://raw.githubusercontent.com/datitran/raccoon_dataset/master/generate_tfrecord.py -O /content/generate_tfrecord.py\n",
        "print(\"âœ… generate_tfrecord.py å·²ä¸‹è¼‰\")\n",
        "\n",
        "# å»ºç«‹ label_map.pbtxt\n",
        "label_map = \"\"\"item {\n",
        "  id: 1\n",
        "  name: 'apple'\n",
        "}\n",
        "\"\"\"\n",
        "with open(\"/content/annotations/label_map.pbtxt\", \"w\") as f:\n",
        "    f.write(label_map)\n",
        "print(\"âœ… label_map.pbtxt å·²å»ºç«‹\")\n",
        "\n",
        "# æª¢æŸ¥ train/test ä¸­çš„ .xml æª”æ¡ˆæ•¸é‡\n",
        "import glob\n",
        "train_xmls = glob.glob(\"/content/images/train/*.xml\")\n",
        "test_xmls = glob.glob(\"/content/images/test/*.xml\")\n",
        "\n",
        "print(f\"ğŸ“¦ Train XML æ•¸é‡: {len(train_xmls)}\")\n",
        "print(f\"ğŸ“¦ Test XML æ•¸é‡: {len(test_xmls)}\")\n",
        "\n",
        "if len(train_xmls) == 0 and len(test_xmls) == 0:\n",
        "    print(\"âš ï¸ æ²’æœ‰æ‰¾åˆ°ä»»ä½• .xml æ¨™è¨»æª”ï¼Œè«‹ç¢ºèªæª”æ¡ˆæ ¼å¼ï¼\")\n",
        "\n",
        "# ç”¢ç”Ÿ train_labels.csv / test_labels.csv\n",
        "!python3 /content/xml_to_csv.py -i /content/images/train -o /content/annotations/train_labels.csv\n",
        "!python3 /content/xml_to_csv.py -i /content/images/test -o /content/annotations/test_labels.csv\n",
        "\n",
        "# æª¢æŸ¥æ˜¯å¦çœŸçš„ç”¢ç”ŸæˆåŠŸ\n",
        "print(\"\\nğŸ“‚ /content/annotations å…§å®¹ï¼š\")\n",
        "!ls -lh /content/annotations\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXVe03FoNVax",
        "outputId": "50d84f08-e1a6-49d7-e29a-6cb1e1f578ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… è³‡æ–™å¤¾å»ºç«‹å®Œæˆ\n",
            "âœ… xml_to_csv.py å·²ä¸‹è¼‰\n",
            "âœ… generate_tfrecord.py å·²ä¸‹è¼‰\n",
            "âœ… label_map.pbtxt å·²å»ºç«‹\n",
            "ğŸ“¦ Train XML æ•¸é‡: 0\n",
            "ğŸ“¦ Test XML æ•¸é‡: 0\n",
            "âš ï¸ æ²’æœ‰æ‰¾åˆ°ä»»ä½• .xml æ¨™è¨»æª”ï¼Œè«‹ç¢ºèªæª”æ¡ˆæ ¼å¼ï¼\n",
            "Successfully converted xml to csv.\n",
            "Successfully converted xml to csv.\n",
            "\n",
            "ğŸ“‚ /content/annotations å…§å®¹ï¼š\n",
            "total 4.0K\n",
            "-rw-r--r-- 1 root root 33 Nov  5 05:07 label_map.pbtxt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pbtxt_content = \"\"\"item {\n",
        "  id: 1\n",
        "  name: 'apple'\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/object-detection.pbtxt\", \"w\") as f:\n",
        "    f.write(pbtxt_content)\n",
        "\n",
        "print(\"âœ… object-detection.pbtxt å·²å»ºç«‹æ–¼ /content/annotations/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-OITPWgZv3L",
        "outputId": "09aa78f2-6c61-4778-b09e-7307a35d681b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… object-detection.pbtxt å·²å»ºç«‹æ–¼ /content/annotations/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ä¸‹è¼‰ xml_to_csv.py\n",
        "!wget https://raw.githubusercontent.com/datitran/raccoon_dataset/master/xml_to_csv.py -O /content/xml_to_csv.py\n",
        "\n",
        "# ç”¢ç”Ÿ train_labels.csv\n",
        "!python3 /content/xml_to_csv.py -i /content/images/train -o /content/annotations/train_labels.csv\n",
        "\n",
        "# ç”¢ç”Ÿ test_labels.csv\n",
        "!python3 /content/xml_to_csv.py -i /content/images/test -o /content/annotations/test_labels.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-UKABT1zg_r",
        "outputId": "9198ad9f-a900-4b9b-d485-dbaf54690f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-05 05:08:03--  https://raw.githubusercontent.com/datitran/raccoon_dataset/master/xml_to_csv.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1089 (1.1K) [text/plain]\n",
            "Saving to: â€˜/content/xml_to_csv.pyâ€™\n",
            "\n",
            "\r/content/xml_to_csv   0%[                    ]       0  --.-KB/s               \r/content/xml_to_csv 100%[===================>]   1.06K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-11-05 05:08:03 (82.3 MB/s) - â€˜/content/xml_to_csv.pyâ€™ saved [1089/1089]\n",
            "\n",
            "Successfully converted xml to csv.\n",
            "Successfully converted xml to csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python xml_to_csv.py\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_Or22PiL1C1",
        "outputId": "bdc51752-0943-4e3c-e651-27c622723697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully converted xml to csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile xml_to_csv.py\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (\n",
        "                root.find('filename').text,\n",
        "                int(root.find('size/width').text),\n",
        "                int(root.find('size/height').text),\n",
        "                member.find('name').text,\n",
        "                int(member.find('bndbox/xmin').text),\n",
        "                int(member.find('bndbox/ymin').text),\n",
        "                int(member.find('bndbox/xmax').text),\n",
        "                int(member.find('bndbox/ymax').text)\n",
        "            )\n",
        "            xml_list.append(value)\n",
        "\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "\n",
        "def main():\n",
        "    for folder in ['train', 'test']:\n",
        "        xml_path = os.path.join('/content/images', folder)\n",
        "        xml_df = xml_to_csv(xml_path)\n",
        "        output_csv = f'/content/annotations/{folder}_labels.csv'\n",
        "        xml_df.to_csv(output_csv, index=False)\n",
        "        print(f\"âœ… {output_csv} generated!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Df5C35WT6vN",
        "outputId": "440297ed-9a48-486d-c536-06d27d025e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting xml_to_csv.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python xml_to_csv.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lIxAkcKTpjs",
        "outputId": "373e4a7c-7926-4e24-be60-c3ed355e3592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… /content/annotations/train_labels.csv generated!\n",
            "âœ… /content/annotations/test_labels.csv generated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/generate_tfrecord.py\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from collections import namedtuple\n",
        "\n",
        "# å°‡ class name è½‰ç‚º int\n",
        "def class_text_to_int(row_label):\n",
        "    if row_label == 'apple':\n",
        "        return 1\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# å°‡ CSV æŒ‰ filename åˆ†çµ„\n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(filename)) for filename in gb.groups]\n",
        "\n",
        "# å»ºç«‹ tf.train.Example\n",
        "def create_tf_example(group, path):\n",
        "    img_path = os.path.join(path, group.filename)\n",
        "    if not os.path.exists(img_path):\n",
        "        print(f\"âš ï¸ æ‰¾ä¸åˆ°åœ–ç‰‡: {img_path}\")\n",
        "        return None\n",
        "\n",
        "    with tf.io.gfile.GFile(img_path, 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "    img = Image.open(io.BytesIO(encoded_jpg))\n",
        "    width, height = img.size\n",
        "\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg' if filename.endswith(b'jpg') else b'jpeg'\n",
        "\n",
        "    xmins, xmaxs, ymins, ymaxs, classes_text, classes = [], [], [], [], [], []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
        "        'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
        "        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename])),\n",
        "        'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename])),\n",
        "        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_jpg])),\n",
        "        'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_format])),\n",
        "        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmins)),\n",
        "        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmaxs)),\n",
        "        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymins)),\n",
        "        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymaxs)),\n",
        "        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n",
        "        'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "def main():\n",
        "    for split_type in ['train', 'test']:\n",
        "        csv_input = f'/content/annotations/{split_type}_labels.csv'\n",
        "        image_dir = f'/content/images/{split_type}'\n",
        "        output_path = f'/content/{split_type}.record'\n",
        "\n",
        "        if not os.path.exists(csv_input):\n",
        "            print(f\"âš ï¸ CSV ä¸å­˜åœ¨: {csv_input}\")\n",
        "            continue\n",
        "\n",
        "        examples = pd.read_csv(csv_input)\n",
        "        if examples.empty:\n",
        "            print(f\"âš ï¸ CSV ç‚ºç©º: {csv_input}, ç„¡æ³•ç”Ÿæˆ TFRecord\")\n",
        "            continue\n",
        "\n",
        "        grouped = split(examples, 'filename')\n",
        "        with tf.io.TFRecordWriter(output_path) as writer:\n",
        "            for group in grouped:\n",
        "                tf_example = create_tf_example(group, image_dir)\n",
        "                if tf_example:\n",
        "                    writer.write(tf_example.SerializeToString())\n",
        "        print(f'âœ… TFRecord saved: {output_path}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-cOZoBpUWwd",
        "outputId": "af65e7e3-8367-4798-9f31-8de5abfb745a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/generate_tfrecord.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=train.record --image_dir=images/train\n",
        "!python3 generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=test.record --image_dir=images/test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEs40VcmYXYo",
        "outputId": "05099114-059a-4543-ecaa-2e136dc674d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-05 05:08:21.932031: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762319301.952061     807 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762319301.958367     807 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762319301.973686     807 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762319301.973734     807 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762319301.973742     807 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762319301.973746     807 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-05 05:08:21.978409: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "âš ï¸ CSV ç‚ºç©º: /content/annotations/train_labels.csv, ç„¡æ³•ç”Ÿæˆ TFRecord\n",
            "âš ï¸ CSV ç‚ºç©º: /content/annotations/test_labels.csv, ç„¡æ³•ç”Ÿæˆ TFRecord\n",
            "2025-11-05 05:08:30.154766: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762319310.174506     853 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762319310.180608     853 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762319310.195300     853 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762319310.195326     853 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762319310.195330     853 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762319310.195335     853 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-05 05:08:30.199680: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "âš ï¸ CSV ç‚ºç©º: /content/annotations/train_labels.csv, ç„¡æ³•ç”Ÿæˆ TFRecord\n",
            "âš ï¸ CSV ç‚ºç©º: /content/annotations/test_labels.csv, ç„¡æ³•ç”Ÿæˆ TFRecord\n"
          ]
        }
      ]
    }
  ]
}